{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebook 03, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. [Bing Chat](http://chat.bing.com/) is a search engine with a GPT-4 model that utilizes the content of search results to provide context and deliver accurate responses to queries.\n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With Bing Chat, this is possible, as the LLM can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "The aim of this Notebook is to demonstrate how we can \"provide memory\" to the LLM by utilizing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from openai.error import OpenAIError\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from app.utils import (\n",
    "    get_search_results,\n",
    "    order_search_results,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    embed_docs,\n",
    "    search_docs,\n",
    "    get_answer,\n",
    ")\n",
    "\n",
    "from app.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_CHAT_PROMPT\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Don't mess with this unless you really know what you are doing\n",
    "AZURE_SEARCH_API_VERSION = '2021-04-30-Preview'\n",
    "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "\n",
    "# Change these below with your own services credentials\n",
    "AZURE_SEARCH_ENDPOINT =\"ENTER YOUR VALUE\"\n",
    "AZURE_SEARCH_KEY = \"ENTER YOUR VALUE\"\n",
    "AZURE_OPENAI_ENDPOINT = \"ENTER YOUR VALUE\"\n",
    "AZURE_OPENAI_API_KEY = \"ENTER YOUR VALUE\"\n",
    "AZURE_COSMOSDB_ENDPOINT = \"ENTER YOUR VALUE\"\n",
    "AZURE_COSMOSDB_NAME = \"ENTER YOUR VALUE\"\n",
    "AZURE_COSMOSDB_CONTAINER_NAME = \"ENTER YOUR VALUE\"\n",
    "AZURE_COMOSDB_CONNECTION_STRING = \"ENTER YOUR VALUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION\n",
    "os.environ[\"AZURE_SEARCH_KEY\"] = AZURE_SEARCH_KEY\n",
    "os.environ[\"AZURE_SEARCH_ENDPOINT\"] = AZURE_SEARCH_ENDPOINT\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"AZURE_COSMOSDB_ENDPOINT\"]=  AZURE_COSMOSDB_ENDPOINT\n",
    "os.environ[\"AZURE_COSMOSDB_NAME\"]=  AZURE_COSMOSDB_NAME\n",
    "os.environ[\"AZURE_COSMOSDB_CONTAINER_NAME\"]=  AZURE_COSMOSDB_CONTAINER_NAME\n",
    "os.environ[\"AZURE_COMOSDB_CONNECTION_STRING\"]=  AZURE_COMOSDB_CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning?\"\n",
    "FOLLOW_UP_QUESTION = \"Can you rephrase what you just said?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "MODEL = \"gpt-35-turbo\"\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Game playing: Reinforcement learning has been successfully applied to game playing, such as AlphaGo and AlphaZero, which have defeated world champions in the games of Go, chess, and shogi.\n",
       "\n",
       "2. Robotics: Reinforcement learning can be used to train robots to perform complex tasks, such as grasping objects, navigating through environments, and manipulating tools.\n",
       "\n",
       "3. Autonomous vehicles: Reinforcement learning can be used to train autonomous vehicles to make decisions based on real-time data, such as traffic conditions, weather, and road obstacles.\n",
       "\n",
       "4. Personalized recommendations: Reinforcement learning can be used to personalize recommendations for products, services, and content based on user behavior and preferences.\n",
       "\n",
       "5. Finance: Reinforcement learning can be used to optimize investment portfolios, detect fraud, and predict market trends.\n",
       "\n",
       "6. Healthcare: Reinforcement learning can be used to optimize treatment plans for patients with chronic conditions, such as diabetes and heart disease.\n",
       "\n",
       "7. Advertising: Reinforcement learning can be used to optimize ad placement and targeting, based on user behavior and engagement.\n",
       "\n",
       "8. Industrial automation: Reinforcement learning can be used to optimize manufacturing processes, reduce waste, and improve product quality."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "response = chain.run(QUESTION)\n",
    "printmd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I cannot remember what I just said as I do not have the ability to retain memory. However, if you provide me with the specific sentence or phrase that you want me to rephrase, I will be happy to assist you.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "chain.run(FOLLOW_UP_QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "                {history}\n",
    "                Human: {question}\n",
    "                AI:\n",
    "            \"\"\"\n",
    "    )\n",
    "chain = LLMChain(llm=llm, prompt=hist_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here are some examples of how reinforcement learning can be applied in various industries: game playing, robotics, autonomous vehicles, personalized recommendations, finance, healthcare, advertising, and industrial automation. For instance, reinforcement learning can be used to train robots to perform complex tasks, optimize investment portfolios, and personalize ad placement based on user behavior and engagement.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b27c45-7fbb-40da-a2e3-61e66a8e49b0",
   "metadata": {},
   "source": [
    "In order to not duplicate code, we have put many of the code used in Notebook 3 into functions. These functions are in the app/utils.py and app/prompts.py files This way we can use these functios in the app that we will build later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index1_name, index2_name]\n",
    "\n",
    "agg_search_results = get_search_results(QUESTION, indexes)\n",
    "ordered_results = order_search_results(agg_search_results, reranker_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom token limit for gpt-35-turbo : 3000\n",
      "Combined docs tokens count: 80428\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    for page in value[\"chunks\"]:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": value[\"location\"]}))\n",
    "\n",
    "# Calculate number of tokens of our docs\n",
    "tokens_limit = model_tokens_limit(MODEL)\n",
    "\n",
    "if(len(docs)>0):\n",
    "    num_tokens = num_tokens_from_docs(docs)\n",
    "    print(\"Custom token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Combined docs tokens count:\",num_tokens)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26d7540-feb8-4581-849e-003f4bf2a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count after similarity search: 4693\n",
      "Chain Type selected: map_reduce\n",
      "CPU times: user 19.7 s, sys: 2.38 s, total: 22.1 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if num_tokens > tokens_limit:\n",
    "    index = embed_docs(docs)\n",
    "    top_docs = search_docs(index,QUESTION)\n",
    "    \n",
    "    # Now we need to recalculate the tokens count of the top results from similarity vector search\n",
    "    # in order to select the chain type: stuff or map_reduce\n",
    "    \n",
    "    num_tokens = num_tokens_from_docs(top_docs)   \n",
    "    print(\"Token count after similarity search:\", num_tokens)\n",
    "    chain_type = \"map_reduce\" if num_tokens > tokens_limit else \"stuff\"\n",
    "    \n",
    "else:\n",
    "    # if total tokens is less than our limit, we don't need to vectorize and do similarity search\n",
    "    top_docs = docs\n",
    "    chain_type = \"stuff\"\n",
    "    \n",
    "print(\"Chain Type selected:\", chain_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The documents provide information on techniques and theories related to reinforcement learning, but do not directly mention any specific use cases for reinforcement learning. However, with appropriate biases, complex reinforcement-learning problems can eventually be solvable, and the algorithms discussed in the documents can be used for reinforcement learning in various applications. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the answer\n",
    "response = get_answer(docs=top_docs, query=QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d",
   "metadata": {},
   "source": [
    "And if we ask the follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no information provided in the given content to answer the question.\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_answer(docs=top_docs,  query=FOLLOW_UP_QUESTION, language=\"English\",deployment=MODEL, chain_type=chain_type)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fa6e6-226c-400f-a504-30255385f43b",
   "metadata": {},
   "source": [
    "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
    "\n",
    "**Now let's add memory to it:**\n",
    "\n",
    "Reference: https://python.langchain.com/en/latest/modules/memory/examples/adding_memory_chain_multiple_inputs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning can be used in a variety of applications, such as robotics, game playing, and recommendation systems. For example, AlphaGo, a computer program developed by Google DeepMind, uses reinforcement learning to play the board game Go at a world-class level. In robotics, reinforcement learning can be used to teach robots how to perform complex tasks, such as grasping objects or navigating through environments. It can also be used in recommendation systems to optimize user engagement and satisfaction. However, the specific use cases for reinforcement learning depend on the problem domain and the available data. Sources: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
    "\n",
    "response = get_answer(docs=top_docs, query=QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf28927b-d9ee-4412-bb07-13e055e832a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reinforcement learning has many use cases, including robotics, game playing, and recommendation systems. For example, Google DeepMind's AlphaGo program uses reinforcement learning to play Go at a world-class level. In robotics, reinforcement learning can be used to teach robots complex tasks, such as grasping objects or navigating through environments. It can also be used in recommendation systems to optimize user engagement and satisfaction. However, the specific use cases for reinforcement learning depend on the problem domain and available data. Additionally, there is a trade-off between exploration and exploitation in reinforcement learning, where the dilemma is between selecting actions to maximize the expected return according to the current world model and improving the world model to potentially achieve a higher expected return. This concept has been extensively studied, and optimal decision thresholds for the multi-armed bandit problem have been derived. These thresholds depend on the reward horizon, uncertainty, and the need for exploration. Sources: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf. \\nSUGGESTION: Do you have any other questions about reinforcement learning?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I couldn't find any relevant information in the provided sources to answer your question. Is there anything else I can help you with? Sources: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf. \\nSUGGESTION: Do you have any other questions or topics you would like to discuss?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(docs=top_docs, query=\"Thank you\", language=\"English\", deployment=MODEL, chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74",
   "metadata": {},
   "source": [
    "Let's check our memory to see that it's keeping the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1279692c-7eb0-4300-8a66-c7025f02c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Tell me some use cases for reinforcement learning?\\nAI: Reinforcement learning can be used in a variety of applications, such as robotics, game playing, and recommendation systems. For example, AlphaGo, a computer program developed by Google DeepMind, uses reinforcement learning to play the board game Go at a world-class level. In robotics, reinforcement learning can be used to teach robots how to perform complex tasks, such as grasping objects or navigating through environments. It can also be used in recommendation systems to optimize user engagement and satisfaction. However, the specific use cases for reinforcement learning depend on the problem domain and the available data. Sources: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf.\\nHuman: Can you rephrase what you just said?\\nAI: Reinforcement learning has many use cases, including robotics, game playing, and recommendation systems. For example, Google DeepMind's AlphaGo program uses reinforcement learning to play Go at a world-class level. In robotics, reinforcement learning can be used to teach robots complex tasks, such as grasping objects or navigating through environments. It can also be used in recommendation systems to optimize user engagement and satisfaction. However, the specific use cases for reinforcement learning depend on the problem domain and available data. Additionally, there is a trade-off between exploration and exploitation in reinforcement learning, where the dilemma is between selecting actions to maximize the expected return according to the current world model and improving the world model to potentially achieve a higher expected return. This concept has been extensively studied, and optimal decision thresholds for the multi-armed bandit problem have been derived. These thresholds depend on the reward horizon, uncertainty, and the need for exploration. Sources: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf. \\nSUGGESTION: Do you have any other questions about reinforcement learning?\\nHuman: Thank you\\nAI: I'm sorry, I couldn't find any relevant information in the provided sources to answer your question. Is there anything else I can help you with? Sources: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf. \\nSUGGESTION: Do you have any other questions or topics you would like to discuss?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87405173",
   "metadata": {},
   "source": [
    "## Using CosmosDB as persistent memory\n",
    "\n",
    "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
    "\n",
    "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
    "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7131daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CosmosDB instance from langchain cosmos class.\n",
    "\n",
    "SESSION_ID = '001'  # this isstring value, normally you need to provide the user session id. As an example I have provided '001' as a session id\n",
    "USER_ID = 'dummy01' # this is string value, normally you need to provide the user id. As an example I have provided 'dummy01' as a user id\n",
    "\n",
    "cosmos = CosmosDBChatMessageHistory(\n",
    "    cosmos_endpoint=AZURE_COSMOSDB_ENDPOINT,\n",
    "    cosmos_database=AZURE_COSMOSDB_NAME,\n",
    "    cosmos_container=AZURE_COSMOSDB_CONTAINER_NAME,\n",
    "    connection_string=AZURE_COMOSDB_CONNECTION_STRING,\n",
    "    session_id=SESSION_ID,\n",
    "    user_id=USER_ID\n",
    "    )\n",
    "\n",
    "# prepare the cosmosdb instance\n",
    "cosmos.prepare_cosmos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Memory Object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ceb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning has a variety of use cases such as game playing, robotics, recommendation systems, and autonomous driving. However, the specific use cases are not mentioned in the provided portion of the document. You can find more information on the topic in this source: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing using our Question\n",
    "response = get_answer(docs=top_docs, query=QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a5ff826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize for the confusion in my previous response. To rephrase, reinforcement learning can be used in various fields such as game playing, robotics, recommendation systems, and autonomous driving. However, the specific use cases are not mentioned in the provided portion of the document. If you would like to learn more about this topic, I recommend checking out this source: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf. Additionally, there is a trade-off between exploration and exploitation in reinforcement learning, where the dilemma is between selecting actions to maximize the expected return according to the current world model and improving the world model to potentially achieve a higher expected return. This concept has been studied extensively, with various approaches to finding optimal solutions for the multi-armed bandit problem. The optimal action selection mechanism will depend on the problem formulation, and the exploration/exploitation tradeoff should be viewed in terms of problem and model definition. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be1620fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're welcome! Let me know if you have any other questions. \\nSOURCES: N/A\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(docs=top_docs, query=\"Thank you\", language=\"English\", deployment=MODEL, chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1d7688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me some use cases for reinforcement learning?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Reinforcement learning has a variety of use cases such as game playing, robotics, recommendation systems, and autonomous driving. However, the specific use cases are not mentioned in the provided portion of the document. You can find more information on the topic in this source: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Can you rephrase what you just said?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='I apologize for the confusion in my previous response. To rephrase, reinforcement learning can be used in various fields such as game playing, robotics, recommendation systems, and autonomous driving. However, the specific use cases are not mentioned in the provided portion of the document. If you would like to learn more about this topic, I recommend checking out this source: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf. Additionally, there is a trade-off between exploration and exploitation in reinforcement learning, where the dilemma is between selecting actions to maximize the expected return according to the current world model and improving the world model to potentially achieve a higher expected return. This concept has been studied extensively, with various approaches to finding optimal solutions for the multi-armed bandit problem. The optimal action selection mechanism will depend on the problem formulation, and the exploration/exploitation tradeoff should be viewed in terms of problem and model definition. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/9605/9605103v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0604/0604010v1.pdf', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Thank you', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"You're welcome! Let me know if you have any other questions. \\nSOURCES: N/A\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load message from cosmosdb\n",
    "cosmos.load_messages()\n",
    "cosmos.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook 05 explains and solves the tabular problem and the concept of Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9cbd8-612d-4e3b-957c-7c829d84cad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
